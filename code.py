# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11R6mJrwRp2lMxM7Enh3oH68vB2DRVdq9
"""

import selenium.webdriver as webdriver
from bs4 import BeautifulSoup
import time
import re
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.edge.service import Service
from selenium.webdriver.edge.options import Options

driver =webdriver.Edge(executable_path="msedgedriver.exe")
driver.implicitly_wait(0.5)

driver.get("https://www.linkedin.com/login?")
driver.implicitly_wait(10)

username = driver.find_element('id',"username")
username.send_keys("enter your user name here****")

pword = driver.find_element('id',"password")
pword.send_keys("Enter your password here***")

driver.find_element(By.XPATH,"//button[@type='submit']").click()
profile_url = "paste the linked post link here.."
driver.get(profile_url)

#wait for 5 secound to load the profile
time.sleep(5)
show_likes=driver.find_element_by_class_name("social-details-social-counts__reactionscount")
print(show_likes)
show_likes.click()
# --------------------for roll the list of all who like the post----------------------

start = time.time()
# will be used in the while loop
initialScroll = 0
finalScroll = 1000
count = 1
while True:

 #wait untill the page is loaded
 time.sleep(5)

 elements = driver.find_elements_by_xpath("//*[contains(@class, 'display-flex') and
contains(@class, 'p5')]")
 if elements:

   element = elements[0]
 else:

   print("Class 'display-flex p5' not found on the page")
 
 element.click()
 driver.execute_script(f"window.scrollTo({initialScroll}, {finalScroll})")

 # assign initial scroll with finalScroll variable
 initialScroll = finalScroll
 finalScroll += 1000
 print(elements[0])
 
 # wait for 4 sec so data can load
 time.sleep(4)
 end = time.time()

 # We will scroll for 60 seconds.
 if round(end - start) > 60:
 break
details = driver.page_source
soup = BeautifulSoup(details, 'lxml')

#print(name1)
only_name = [tag.find('span', attrs={'dir': 'ltr'}).text for tag in
soup.find_all('div', class_='artdeco-entity-lockup__title')]

only_position= [tag.text.strip() for tag in soup.find_all('div', class_='artdecoentity-lockup__caption')]

data=dict(map(lambda i,j : (i,j),only_name,only_position))
print(data)